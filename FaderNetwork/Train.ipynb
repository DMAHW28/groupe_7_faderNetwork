{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4823bd68-3a74-464b-bcd2-00c57165bae4",
   "metadata": {},
   "source": [
    "# Entraînement Fader Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d893562b-933e-4239-92e8-f47f3ba2c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# Ajouter le chemin racine au PYTHONPATH pour pouvoir importer les modules personnalisés\n",
    "# sys.path.append(os.path.abspath('.'))\n",
    "\n",
    "from Models.fader_network import FaderNetwork\n",
    "from Models.discriminator import Discriminator\n",
    "from Data.preprocess import create_data_file\n",
    "from Training.train import Evaluator, Trainer\n",
    "from Training.losses import attr_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4410d974-0ea9-4772-84df-c2be149f3266",
   "metadata": {},
   "source": [
    "## Configuration des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19061e95-9f08-4f3d-9465-17bf59cee57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_attrs = ['Smiling', 'Male', 'Eyeglasses', 'Young', 'Mouth_Slightly_Open']\n",
    "num_attributes = len(selected_attrs)\n",
    "latent_dim = 512\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "lr = 0.002\n",
    "beta1 = 0.5\n",
    "step = 202599 # On selectionne toute les images de la BD\n",
    "n_img = 202599 # Toute les images de la base de données \n",
    "generator = create_data_file(selected_attrs, step = step, batch_size = 32, n_img = n_img)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Utilisation du device : {device}\")\n",
    "\n",
    "# Calcul du scheduler_steps en fonction de l'ensemble d'entraînement\n",
    "total_iterations = ((step/2) // batch_size) * epochs\n",
    "scheduler_steps = int(total_iterations*0.3)\n",
    "print(f\"Total iterations for scheduler: {scheduler_steps}\")\n",
    "\n",
    "# Initialiser les modèles\n",
    "auto_encoder = FaderNetwork(attribute_dim=num_attributes, attributes=selected_attrs).to(device)\n",
    "discriminator = Discriminator(n_attr=num_attributes, attributes=selected_attrs).to(device)\n",
    "\n",
    "print(\"Modèles initialisés.\")\n",
    "\n",
    "# Trainer and Evaluator\n",
    "trainer = Trainer(auto_encoder, discriminator, scheduler_steps)\n",
    "evaluator = Evaluator(auto_encoder, discriminator)\n",
    "\n",
    "print(\"Trainer/Evaluator initialisés.\")\n",
    "\n",
    "#les optimisateurs\n",
    "optimizer_enc_dec = optim.Adam(auto_encoder.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizer_dis = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "#fonctions de perte\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "ce_loss_fn = attr_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fd9ebe-b06b-43de-8382-cfa8fae5226c",
   "metadata": {},
   "source": [
    "## Début de l'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f99912-d05b-4ffe-a5c6-3c2f387a92cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir='./logs/fader_networks')\n",
    "\n",
    "# best_val_loss = float('inf')  # Pour suivre la meilleure perte de validation\n",
    "\n",
    "for i, base_loader in enumerate(generator):\n",
    "    (train_loader, valid_loader, test_loader) = base_loader\n",
    "    for epoch in range(1, epochs+1):\n",
    "\n",
    "        trainer.init_parameters()\n",
    "        evaluator.init_parameters()\n",
    "\n",
    "        for (X, y) in tqdm(train_loader, desc=f\"Epoch : {epoch}\"):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            trainer.latent_step(X=X, y=y, criterion=ce_loss_fn, optim=optimizer_dis)\n",
    "            trainer.ae_step(X=X, y=y, criterion_ae=mse_loss_fn, criterion_latent=ce_loss_fn, optim=optimizer_enc_dec)\n",
    "        \n",
    "        avg_ae_loss = trainer.ae_train_loss / len(train_loader)\n",
    "        avg_dis_loss = trainer.latent_train_loss / len(train_loader)\n",
    "        \n",
    "       \n",
    "        # Log dans TensorBoard\n",
    "        writer.add_scalar('Loss/AE_Train', avg_ae_loss, epoch)\n",
    "        writer.add_scalar('Loss/Discriminator_Train', avg_dis_loss, epoch)\n",
    "        \n",
    "        # Afficher les pertes de l'époque\n",
    "        print(f\"Epoch [{epoch}/{epochs}] | AE_Train: {avg_ae_loss:.4f} | Discriminator_Train: {avg_dis_loss:.4f}\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for l, (X, y) in enumerate(valid_loader):\n",
    "                X, y = X.to(device), y.to(device)\n",
    "                evaluator.latent_step(X=X, y=y, criterion=ce_loss_fn)\n",
    "                _ = evaluator.ae_step(X=X, y=y, criterion=mse_loss_fn)\n",
    "            \n",
    "            avg_val_ae_loss = evaluator.ae_evaluate_loss / len(valid_loader)\n",
    "            avg_val_dis_loss = evaluator.latent_evaluate_loss / len(valid_loader)\n",
    "            accuracy_dis = evaluator.latent_evaluate_accuracy / (len(valid_loader.dataset) * num_attributes)\n",
    "        \n",
    "            # Log dans TensorBoard\n",
    "            writer.add_scalar('Validation/AE_Validation', avg_val_ae_loss, epoch)\n",
    "            writer.add_scalar('Validation/Discriminator_Validation', avg_val_dis_loss, epoch)\n",
    "            writer.add_scalar('Validation/Accuracy_Discriminator', accuracy_dis, epoch)\n",
    "            \n",
    "        print(f\"Epoch Val [{epoch}/{epochs}] | AE_Validation: {avg_val_ae_loss:.4f} | Discriminator_Validation: {avg_val_dis_loss:.4f} | accuracy_dis: {accuracy_dis:.6f}\")\n",
    "                        \n",
    "        # Enregistrement des modèles\n",
    "        # os.makedirs('./Models/trained_model/', exist_ok=True)\n",
    "        # torch.save(auto_encoder.state_dict(), f'./Models/trained_model/TrainBD_50_100_{i}/auto_encoder_epoch_{epoch}.pth')\n",
    "        # torch.save(discriminator.state_dict(), f'./Models/trained_model/TrainBD_50_100_{i}/discriminator_epoch_{epoch}.pth')\n",
    "        # print(f\"Modèles enregistrés pour l'époque {epoch}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
